---
layout: default
title: "Research"
permalink: /research/
---
# Research

## Publications
<hr style="border:1px solid gray">
<p style = "text-indent: -2em; padding-left: 2em;">
<a href="https://journals.sagepub.com/doi/pdf/10.1177/00018392251313737" target="_blank">"Methodological Pluralism and Innovation in Data-Driven Organizations"</a> with Rory McDonald. 2025. <i>Administrative Science Quarterly</i>
</p>
<p style="margin-left:5%;font-size:95%;">
  ** "Best Paper" at Strategy Science Conference 2022<br> 
  ** "Best Paper" at Wharton Innovation Doctoral Symposium 2022<br>
</p>
<ul>
<details><summary>Click to display Abstract</summary>Prior research on data-driven innovation, which assumes quantitative analysis as the default, suggests a tradeoff: Organizations that rely heavily on data-driven analysis tend to produce familiar, incremental innovations with moderate commercial potential, at the expense of risky, novel breakthroughs or hit products. We argue that this tradeoff does not hold when quantitative and qualitative analysis are used together. Organizations that substantially rely on both types of analysis in the new-product innovation process will benefit by triangulating quantifiably verifiable demand (which prompts more moderate successes but fewer hits) with qualitatively discernible potential (which prompts more novelty but more flops). Although relying primarily on either type of analysis has little impact on overall new-product sales due to the countervailing strengths and weaknesses inherent in each, together they have a complementary positive effect on new-product sales as each compensates for the weaknesses of the other. Drawing on a unique dataset of 3,768 new-product innovations from NielsenIQ linked to employee résumé job descriptions from 55 consumer-product firms, we find support for our hypothesis. The highest sales and number of hits were observed in organizations that demonstrated methodological pluralism: substantial reliance on both types of analyses. Further mixed-method research examining related outcomes—hits, flops, and novelty—corroborates our theory and confirms its underlying mechanisms.</details>
</ul>
<hr style="border:none;height:1px;"> 
<p style = "text-indent: -2em; padding-left: 2em;">
<a href="https://pubsonline.informs.org/doi/abs/10.1287/orsc.2021.1554" target="_blank">"Algorithm-Augmented Work and Domain Experience: The Countervailing Forces of Ability and Aversion"</a> with Raj Choudhury. 2022. <i>Organization Science</i> 33(1), 149-169.</p>  
<p style="margin-left:5%;font-size:95%;">**"Best PhD Student Paper" at SMS conference 2020</p>  
<ul>
<details><summary>Click to display Abstract</summary>Past research offers mixed perspectives on whether domain experience helps or hurts algorithm-augmented worker performance. Reconciling these perspectives, we theorize that intermediate levels of domain experience are optimal for algorithm-augmented performance, due to the interplay between two countervailing forces—ability and aversion. Although domain experience can increase performance via increased ability to complement algorithmic advice (e.g., identifying inaccurate predictions), it can also decrease performance via increased aversion to accurate algorithmic advice. Because ability developed through learning by doing increases at a decreasing rate, and algorithmic aversion is more prevalent among experts, we theorize that algorithm-augmented performance will first rise with increasing domain experience, then fall. We test this by exploiting a within-subjects experiment in which corporate information technology support workers were assigned to resolve problems both manually and using an algorithmic tool. We confirm that the difference between performance with the algorithmic tool versus without the tool was characterized by an inverted U-shape over the range of domain experience. Only workers with moderate domain experience did significantly better using the algorithm than resolving tickets manually. These findings highlight that, even if greater domain experience increases workers’ ability to complement algorithms, domain experience can also trigger other mechanisms that overcome the positive ability effect and inhibit performance. Additional analyses and participant interviews suggest that, even though the highest experience workers had the greatest ability to complement the algorithmic tool, they rejected its advice because they felt greater accountability for possible unintended consequences of accepting algorithmic advice.</details>
</ul>
<hr style="border:none;height:1px;"> 
<p style = "text-indent: -2em; padding-left: 2em;">
<a href="https://pubsonline.informs.org/doi/abs/10.1287/stsc.2021.0130" target="_blank">"A Spanner in the Works: Category-Spanning Entrants and Audience Valuation of Incumbents"</a> with Rory McDonald. 2022. <i>Strategy Science</i>.</p>
<ul>
<details><summary>Click to display Abstract</summary>Previous work has examined how audiences evaluate category-spanning organizations, but little is known about how their entrance affects evaluations of other, proximate organizations. We posit that the emergence of category-spanning entrants signals the advent of an altered future state—and seeds doubt about incumbents’ prospects in a reordered industry-categorization scheme. We test this hypothesis by treating announcements of funding for startups as an information shock to investors evaluating incumbent financial service providers between 2010 and 2017—a period marked by atypical category combinations at FinTech startups. We find that announcements by startups that embodied unusual combinations of categories resulted in lower cumulative average returns for incumbents, both in absolute terms and in comparison with typical startups. Our theory and results contribute to research on categorization in markets and to theories of disruptive innovation and industry evolution.</details>
</ul>
<hr style="border:none;height:1px;"> 
<p style = "text-indent: -2em; padding-left: 2em;">
<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/smj.3215" target="_blank">"Machine Learning for Pattern Discovery in Management Research"</a> with Raj Choudhury and Michael Endres. 2021. <i>Strategic Management Journal</i> 42(1), 30-57.</p>
<ul>
<details><summary>Click to display Abstract</summary>Supervised machine learning (ML) methods are a powerful toolkit for discovering robust patterns in quantitative data. The patterns identified by ML could be used for exploratory inductive or abductive research, or for post hoc analysis of regression results to detect patterns that may have gone unnoticed. However, ML models should not be treated as the result of a deductive causal test. To demonstrate the application of ML for pattern discovery, we implement ML algorithms to study employee turnover at a large technology company. We interpret the relationships between variables using partial dependence plots, which uncover surprising nonlinear and interdependent patterns between variables that may have gone unnoticed using traditional methods. To guide readers evaluating ML for pattern discovery, we provide guidance for evaluating model performance, highlight human decisions in the process, and warn of common misinterpretation pitfalls. The Supporting Information section provides code and data to implement the algorithms demonstrated in this article</details>
</ul>
<hr style="border:none;height:1px;">
<p style = "text-indent: -2em; padding-left: 2em;">
<a href="https://link.springer.com/article/10.1057/s41267-022-00570-2" target="_blank">"From Local Modification to Global Innovation: How Research Units in Emerging Economies Innovate for the World"</a> with Shad Morris, James Oldroyd, Daniel Chng, and Jian Han. 2023. <i>Journal of International Business Studies</i>. </p>
<ul>
<details><summary>Click to display Abstract</summary>More and more companies are turning to emerging markets as sources of global innovation to help transform business and society. However, building innovation capabilities in emerging markets is still elusive for most companies. To understand how some companies are successfully building these capabilities, we examined workers within R&amp;D units in China across six foreign multinational corporations. In contrast with prior literature that emphasizes a structural view of who the workers interacted with to innovate, our inductive analysis highlights a behavioral view of how R&amp;D unit personnel interact during the problem and solution search process. We identified two key behaviors associated with the problem and solution search: (1) observing customers in their everyday context, and (2) uncovering general knowledge principles from internal experts. Respectively, these behaviors helped R&amp;D workers to question assumptions about existing products as they relate to customers and to apply useful principles from expert knowledge rather than copying solution templates. Our findings offer an alternative path to building global innovation capabilities in markets where structural constraints exist for the company.</details>
</ul>
<hr style="border:none;height:1px;">

## Working Papers Submitted or Under Review (some titles altered for anonymity)

<hr style="border:1px solid gray">
<p style="text-indent: -2em; padding-left: 2em;">
  <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5239555" target="_blank">"How Well Can AI do Strategy? Empirical Benchmarking Using Strategy Simulations"</a> with Rory McDonald.
</p>
<ul>
  <details><summary>Click to display Abstract</summary>AI research has introduced several benchmarks tracking how large language models (LLMs) have rapidly advanced in lower-level tasks such as math, science, reading comprehension, and coding. Yet no systematic evaluation criteria currently exist to assess LLMs' unaided performance in strategic decision-making. The absence of a reliable benchmark limits strategy scholars' ability to answer fundamental questions about AI's capacity to augment or automate core strategic management decisions. We propose that AI's performance on established strategy teaching simulations offers a promising benchmark, as these exercises replicate the complexity and uncertainty of strategic decision-making in a controlled, validated, and replicable environment. In this paper, we benchmark the performance of OpenAI's models on the Back Bay Battery simulation, a widely used exercise in courses on strategy and innovation. Designed to test decision-making under uncertainty, the simulation requires participants to balance trade-offs between short-term profitability and long-term competitive positioning, while integrating diverse information about customer preferences, competitive moves, and evolving technologies over extended time horizons. We created an interface that allows AI to interact with the simulation without any fine-tuning or prompting beyond the information available within the simulation itself. We find that OpenAI's latest o3-mini model performs on par with MBA students from a top school. Other recent models (GPT-4o, o1-mini), while not as strong as o3-mini, significantly outperform earlier versions (GPT-4, GPT-3.5), although the pace of progress appears to have slowed. Beyond showing that AI can make effective strategic decisions, our simulation-based approach offers a useful empirical benchmark for tracking its future development.
  </details>
</ul>

<hr style="border:none;height:1px;">
<p style = "text-indent: -2em; padding-left: 2em;">
<a href="https://papers.ssrn.com/abstract_id=5084612" target="_blank">"Leap of Faith? How Diffusion Dynamics Obfuscate the Commercial Potential of Novel Innovations"</a>.
 </p>
<p style="margin-left:5%;font-size:95%;">
  ** "Best Paper" at AOM 2024<br>
  ** Finalist for TIM Best Paper Award AOM 2024<br>
</p>
<ul>
<details><summary>Click to display Abstract</summary>This study offers a demand-side explanation for why many novel innovations succeed despite initially small observable market sizes. Diffusion theory suggests that the ambiguity of relatively novel product innovations leads potential customers to base their adoption decisions more heavily on others' adoption. As a result, a significant portion of demand only materializes post-diffusion. I posit that this dynamic obfuscates the true commercial potential of novel innovations when estimates are based on pre-launch observable demand. Agent-based simulations support this theory, showing that novel products outperform non-novel ones with similar initial market sizes. I also explore the model’s implications for firms’ innovation selection processes. The findings complement supply-side strategic innovation theories and highlight the limitations of heavily relying on data-driven, observable market demand in innovation.</details>
</ul>
<hr style="border:none;height:1px;">  
<p style = "text-indent: -2em; padding-left: 2em;">
<strong>"Self-Selection in User Community Feedback and Commercial Performance"</strong> with Rory McDonald and Rob Bremner. 2nd Round Revise and Resubmit at <i>Academy of Management Journal</i>
 </p>
<ul>
<details><summary>Click to display Abstract</summary>Prior research on community innovation demonstrates that incorporating feedback from communities in product development leads to a range of desirable outcomes including more novel and technically superior products with lower development costs.  But, drawing from the sample selection bias literature, we propose that such feedback may dampen commercial success. Due to the voluntary nature of participation, user-communities may attract members with atypical preferences who self-select into the community because of a particular interest in and enthusiasm for the product. We argue that their feedback may not represent the broader addressable market, producing niche signals of market demand. When incorporated into a product, these signals can diminish its broader commercial appeal. Our analysis of quantitative and qualitative data from PC-game development in Steam Early Access confirms our theory: developers that heavily incorporate feedback from relatively unrepresentative communities launch games that are less commercially successful.  We further theorize and empirically explore why unrepresentative feedback is difficult to detect and avoid. Product developers have limited control over who participates in community feedback; the immediate positive reactions to feedback incorporation from users within the community can thus obscure a development trajectory that ultimately dampens commercial success in the broader market.  </details>
</ul>
<hr style="border:none;height:1px;">  
<p style = "text-indent: -2em; padding-left: 2em;">
<strong>"Hierarchy and Experimentation in Startups"</strong> with Todd Hall, Anavir Shermon, and Travis Howell. Revise and Resubmit at <i>Organization Science</i>
</p>
<hr style="border:none;height:1px;">  
<p style = "text-indent: -2em; padding-left: 2em;">
<strong>"Methodological Fit and Entrepreneurship"</strong> with Travis Howell, Anavir Shermon, and Todd Hall. 
</p>
<hr style="border:none;height:1px;">  
<p style = "text-indent: -2em; padding-left: 2em;">
<strong>"How Predictable is Exceptional Growth in Entrepreneurship? Using Machine Learning to Predict Who Joins the Unicorn Venture Club"</strong> with Suresh Kotha, Ben Hallen, Sung Ho Park, and Joseph Shin. Submitted to <i>Academy of Management Journal</i>
</p>
<p style="margin-left:5%;font-size:95%;">
  ** "Best Paper" at AOM 2024<br>
</p>
## Other Works in Progress
<hr style="border:1px solid gray"> 
<p style = "text-indent: -2em; padding-left: 2em;">
 <strong>"Data-driven Decision-making and Organizational Hierarchy"</strong> with Kramer Quist.
</p>
<ul>
<details><summary>Click to display Abstract</summary>This study develops and empirically tests a formal model for how organizational hierarchy affects demand for data-driven decision-making. The model shows that although data can substitute for hierarchy by establishing a framework for consensus, hierarchy also increases demand for data because hierarchies require legible and commensurable results. We empirically validate the model using data from employee profiles on a career networking website. We use job titles to measure the span of control across levels of hierarchy in 61 consumer product organizations, and job descriptions to measure the prevalence of data-driven decision-making. </details>
</ul>

<hr style="border:none;height:1px;">  
<p style = "text-indent: -2em; padding-left: 2em;">
<strong>"Sequencing Entrepreneurial Scaling"</strong> with Aticus Peterson
</p>

<hr style="border:none;height:1px;">  
<p style = "text-indent: -2em; padding-left: 2em;">
<strong>"Cultural authenticity in new ventures as a double-edged sword: a competitive resource and constraint to market scope"</strong> with Rohan Radke and Ming Zhu Wang
</p>

